
<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Intel MPI &mdash; Sheffield HPC Documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css?v=a5c4661c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css?v=0a35405e" />

  
    <link rel="canonical" href="https://docs.hpc.shef.ac.uk/stanage/software/parallel/impi.html" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../../_static/copybutton.js?v=f281be69"></script>
        <script src="../../../_static/design-tabs.js?v=36754332"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="OpenMPI" href="openmpi.html" />
    <link rel="prev" title="Parallel Systems on Stanage" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Sheffield HPC Documentation
              <img src="../../../_static/UOSLogo_Primary_Violet_RGB_small.png" class="logo" alt="Logo"/>
          </a><div>
    <h3>Quick search</h3>
    <!--Setup by JKWM via https://cse.google.com/cse/all-->
    <script async src="https://cse.google.com/cse.js?cx=243e6cd4be08b404b">
    </script>
    <div class="gcse-search"></div>
 </div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../hpc/index.html">Using the HPC Systems</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">Stanage</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../stanage-FAQ-gotchas.html">Stanage FAQ and Gotchas</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">Software on Stanage</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../apps/index.html">Applications on Stanage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../development/index.html">Developing on Stanage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../libs/index.html">Libraries on Stanage</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="index.html">Parallel Systems on Stanage</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">Intel MPI</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#versions">Versions</a></li>
<li class="toctree-l5"><a class="reference internal" href="#examples">Examples</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#example-mpi-performance-testing">Example: MPI Performance testing</a></li>
<li class="toctree-l6"><a class="reference internal" href="#example-using-the-intel-mpi-compilers">Example: Using the Intel MPI compilers</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#installation-notes">Installation notes</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="openmpi.html">OpenMPI</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../cluster_specs.html">Stanage Specifications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../slurm.html">Slurm Scheduler Job Submission info</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../stanage-mfa-setup.html">Stanage TOTP multifactor authentication setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../GPUComputingStanage.html">Using GPUs on Stanage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../bessemer/index.html">Bessemer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../parallel/index.html">Parallel Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../newsletter/index.html">News</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../glossary.html">Glossary of Terms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../other-uk-hpc-resources.html">Access to External UK HPC Facilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../help.html">Need help?</a></li>
<li class="toctree-l1"><a class="reference external" href="https://rcgsheffield.github.io/TUoS-RIT-training-resources/training.html">Courses / Training Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../FAQs.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cheatsheets/index.html">Quick Reference (Cheat Sheets)</a></li>
<li class="toctree-l1"><a class="reference external" href="http://changelog.hpc.shef.ac.uk/">Latest Software / HPC changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../referenceinfo/index.html">Reference Information Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../citing.html">Suggested text for citations and letters of support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../decommissioned/index.html">Decommissioned Clusters</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Sheffield HPC Documentation</a>
      </nav>

      <div class="wy-nav-content">
<!-- <a class="forkme" href="https://github.com/rcgsheffield/sheffield_hpc">
<img alt="Fork me on GitHub" src="../../../_static/img/forkme.png"> 
</a> -->

        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Stanage</a></li>
          <li class="breadcrumb-item"><a href="../index.html">Software on Stanage</a></li>
          <li class="breadcrumb-item"><a href="index.html">Parallel Systems on Stanage</a></li>
      <li class="breadcrumb-item active">Intel MPI</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="intel-mpi">
<span id="impi-stanage"></span><h1>Intel MPI<a class="headerlink" href="#intel-mpi" title="Link to this heading"></a></h1>
<aside class="sidebar">
<p class="sidebar-title">Intel MPI</p>
<dl class="field-list simple">
<dt class="field-odd">URL<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://software.intel.com/en-us/mpi-library">https://software.intel.com/en-us/mpi-library</a></p>
</dd>
</dl>
</aside>
<p>“Intel MPI Library is a multifabric message-passing library
that implements the open-source MPICH specification.
Use the library to create, maintain, and test advanced, complex applications that
perform better on HPC clusters based on Intel® processors.”</p>
<section id="versions">
<h2>Versions<a class="headerlink" href="#versions" title="Link to this heading"></a></h2>
<p>You can load a specific version using one of the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">impi</span><span class="o">/</span><span class="mf">2019.7.217</span><span class="o">-</span><span class="n">iccifort</span><span class="o">-</span><span class="mf">2020.1.217</span>     <span class="c1"># subset of the intel 2020a toolchain</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">impi</span><span class="o">/</span><span class="mf">2019.9.304</span><span class="o">-</span><span class="n">iccifort</span><span class="o">-</span><span class="mf">2020.4.304</span>     <span class="c1"># subset of the intel 2020b toolchain</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">impi</span><span class="o">/</span><span class="mf">2021.2.0</span><span class="o">-</span><span class="n">intel</span><span class="o">-</span><span class="n">compilers</span><span class="o">-</span><span class="mf">2021.2.0</span>  <span class="c1"># subset of the intel 2021a toolchain</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">impi</span><span class="o">/</span><span class="mf">2021.4.0</span><span class="o">-</span><span class="n">intel</span><span class="o">-</span><span class="n">compilers</span><span class="o">-</span><span class="mf">2021.4.0</span>  <span class="c1"># subset of the intel 2021b toolchain</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">impi</span><span class="o">/</span><span class="mf">2021.6.0</span><span class="o">-</span><span class="n">intel</span><span class="o">-</span><span class="n">compilers</span><span class="o">-</span><span class="mf">2022.1.0</span>  <span class="c1"># subset of the intel 2022a toolchain</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">impi</span><span class="o">/</span><span class="mf">2021.7.1</span><span class="o">-</span><span class="n">intel</span><span class="o">-</span><span class="n">compilers</span><span class="o">-</span><span class="mf">2022.2.1</span>  <span class="c1"># subset of the intel 2022b toolchain</span>
</pre></div>
</div>
<p>which implicitly load versions of icc, ifort (and GCC).</p>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Link to this heading"></a></h2>
<p>Two examples are given below, the first assessing the MPI performance and the second demonstrating the use
of the Intel MPI compilers.</p>
<section id="example-mpi-performance-testing">
<h3>Example: MPI Performance testing<a class="headerlink" href="#example-mpi-performance-testing" title="Link to this heading"></a></h3>
<p>A simple test of these modules can be performed by running the built in performance benchmark tests
supplied by Intel. An example of this using 2 cores on one node is given below:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes=1</span>
<span class="c1">#SBATCH --ntasks-per-node=2</span>

module<span class="w"> </span>load<span class="w"> </span>impi/2021.7.1-intel-compilers-2022.2.1

<span class="nv">MACHINEFILE</span><span class="o">=</span><span class="s2">&quot;machinefile.</span><span class="nv">$JOB_ID</span><span class="s2">&quot;</span>

<span class="c1"># Show which node you have been allocated CPU cores on</span>
<span class="nb">echo</span><span class="w"> </span>-e<span class="w"> </span><span class="s2">&quot;\nShow node core allocation:\n&quot;</span>

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;SLURM_JOB_NODELIST=</span><span class="si">${</span><span class="nv">SLURM_JOB_NODELIST</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;SLURM_NNODES=</span><span class="si">${</span><span class="nv">SLURM_NNODES</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;SLURM_NTASKS_PER_NODE=</span><span class="si">${</span><span class="nv">SLURM_NTASKS_PER_NODE</span><span class="p">-1</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;SLURM_CPUS_PER_TASK=</span><span class="si">${</span><span class="nv">SLURM_CPUS_PER_TASK</span><span class="p">-1</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="nb">echo</span><span class="w"> </span>-e<span class="w"> </span><span class="s2">&quot;\nBegin running application:\n&quot;</span>
srun<span class="w"> </span>--export<span class="o">=</span>ALL<span class="w"> </span>IMB-MPI1
</pre></div>
</div>
<p>This will generate output of the form:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Show<span class="w"> </span>node<span class="w"> </span>core<span class="w"> </span>allocation:

<span class="nv">SLURM_JOB_NODELIST</span><span class="o">=</span>node050
<span class="nv">SLURM_NNODES</span><span class="o">=</span><span class="m">1</span>
<span class="nv">SLURM_NTASKS_PER_NODE</span><span class="o">=</span><span class="m">2</span>
<span class="nv">SLURM_CPUS_PER_TASK</span><span class="o">=</span><span class="m">1</span>


Begin<span class="w"> </span>running<span class="w"> </span>application:

<span class="c1">#----------------------------------------------------------------</span>
<span class="c1">#    Intel(R) MPI Benchmarks 2021.4, MPI-1 part</span>
<span class="c1">#----------------------------------------------------------------</span>
<span class="c1"># Date                  : Thu Mar 16 16:00:38 2023</span>
<span class="c1"># Machine               : x86_64</span>
<span class="c1"># System                : Linux</span>
<span class="c1"># Release               : 3.10.0-1160.59.1.el7.x86_64</span>
<span class="c1"># Version               : #1 SMP Wed Feb 23 16:47:03 UTC 2022</span>
<span class="c1"># MPI Version           : 3.1</span>
<span class="c1"># MPI Thread Environment:</span>
</pre></div>
</div>
<p>This is followed by a series of test benchmark results for each of the many tests.</p>
</section>
<section id="example-using-the-intel-mpi-compilers">
<h3>Example: Using the Intel MPI compilers<a class="headerlink" href="#example-using-the-intel-mpi-compilers" title="Link to this heading"></a></h3>
<p>Another simple test of these modules can be performed by compiling and running the example executable
provided by Intel. An example of this using 2 cores is given below:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes=1</span>
<span class="c1">#SBATCH --ntasks-per-node=2</span>

module<span class="w"> </span>load<span class="w"> </span>impi/2021.7.1-intel-compilers-2022.2.1

<span class="c1"># Show which nodes you have been allocated CPU cores on</span>
<span class="nb">echo</span><span class="w"> </span>-e<span class="w"> </span><span class="s2">&quot;\nShow node core allocation:\n&quot;</span>

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;SLURM_JOB_NODELIST=</span><span class="si">${</span><span class="nv">SLURM_JOB_NODELIST</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;SLURM_NNODES=</span><span class="si">${</span><span class="nv">SLURM_NNODES</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;SLURM_NTASKS_PER_NODE=</span><span class="si">${</span><span class="nv">SLURM_NTASKS_PER_NODE</span><span class="p">-1</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;SLURM_CPUS_PER_TASK=</span><span class="si">${</span><span class="nv">SLURM_CPUS_PER_TASK</span><span class="p">-1</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="nb">cd</span><span class="w"> </span>/mnt/parscratch/users/<span class="nv">$USER</span>
cp<span class="w"> </span>-R<span class="w"> </span><span class="nv">$I_MPI_ROOT</span>/test<span class="w"> </span>./<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>chmod<span class="w"> </span><span class="m">700</span><span class="w"> </span>-R<span class="w"> </span><span class="nb">test</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>test/
<span class="c1"># Compiling the C example</span>
mpicc<span class="w"> </span>test.c
<span class="c1"># Alternatively you can compile the fortran example instead</span>
<span class="c1">#mpif90 test.f90</span>

<span class="nb">echo</span><span class="w"> </span>-e<span class="w"> </span><span class="s2">&quot;\nBegin running application:\n&quot;</span>
srun<span class="w"> </span>--export<span class="o">=</span>ALL<span class="w"> </span>/mnt/parscratch/users/<span class="nv">$USER</span>/test/a.out
</pre></div>
</div>
<p>This will generate output of the form:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Show<span class="w"> </span>node<span class="w"> </span>core<span class="w"> </span>allocation:

<span class="nv">SLURM_JOB_NODELIST</span><span class="o">=</span>node051
<span class="nv">SLURM_NNODES</span><span class="o">=</span><span class="m">1</span>
<span class="nv">SLURM_NTASKS_PER_NODE</span><span class="o">=</span><span class="m">2</span>
<span class="nv">SLURM_CPUS_PER_TASK</span><span class="o">=</span><span class="m">1</span>

Begin<span class="w"> </span>running<span class="w"> </span>application:

Hello<span class="w"> </span>world:<span class="w"> </span>rank<span class="w"> </span><span class="m">0</span><span class="w"> </span>of<span class="w"> </span><span class="m">2</span><span class="w"> </span>running<span class="w"> </span>on<span class="w"> </span>node051.pri.stanage.alces.network
Hello<span class="w"> </span>world:<span class="w"> </span>rank<span class="w"> </span><span class="m">1</span><span class="w"> </span>of<span class="w"> </span><span class="m">2</span><span class="w"> </span>running<span class="w"> </span>on<span class="w"> </span>node051.pri.stanage.alces.network
</pre></div>
</div>
</section>
</section>
<section id="installation-notes">
<h2>Installation notes<a class="headerlink" href="#installation-notes" title="Link to this heading"></a></h2>
<p>This section is primarily for administrators of the system. Intel MPI has been installed using the default Easybuild config files but with the following tweaks made via EasyBuild hooks:</p>
<ul class="simple">
<li><dl class="simple">
<dt>Module files are patched so that</dt><dd><ul>
<li><p>they instruct Slurm at runtime (via <code class="docutils literal notranslate"><span class="pre">SLURM_MPI_TYPE=pmi2</span></code>) that the PMI2 API is to be used for launching remote processes using <code class="docutils literal notranslate"><span class="pre">srun</span></code>,
as Intel MPI currently works better with PMI2 than the newer PMIx APIs.</p></li>
<li><p>for versions greater than 19.0.0 <code class="docutils literal notranslate"><span class="pre">I_MPI_PMI_LIBRARY</span></code> is set to the absolute path to <code class="docutils literal notranslate"><span class="pre">libpmi2.so</span></code> (required by <code class="docutils literal notranslate"><span class="pre">srun</span></code>).</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">mpirun</span></code> executable is patched so that <code class="docutils literal notranslate"><span class="pre">I_MPI_PMI_LIBRARY</span></code> is explicitly <em>unset</em> at execution time, as <code class="docutils literal notranslate"><span class="pre">I_MPI_PMI_LIBRARY</span></code> can only be used with <code class="docutils literal notranslate"><span class="pre">srun</span></code>.</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Parallel Systems on Stanage" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="openmpi.html" class="btn btn-neutral float-right" title="OpenMPI" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, The University of Sheffield.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<footer class="footer">
  <div class="container">
    <div class="left-footer">
         &copy; 2024, The University of Sheffield
       <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/80x15.png" /></a>
    </div>
   
    <div class="centre-footer">
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 7.3.7
    </div>
  </div>
</footer>

</body>
</html>